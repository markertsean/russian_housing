{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import remap_values      as rv\n",
    "import df_visualizations as dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# price_doc new sale price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv( 'inp_data/train.csv' )\n",
    "test_df  = pd.read_csv( 'inp_data/test.csv'  )\n",
    "\n",
    "target_price = np.log10( train_df       ['price_doc'] .copy() )\n",
    "train_df     =           train_df.drop( ['price_doc'] , axis=1 )\n",
    "\n",
    "big_df = train_df.append( test_df ).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30471, 291)\n",
      "(7662, 291)\n"
     ]
    }
   ],
   "source": [
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine some values\n",
    "big_df['N_build']    = big_df[ ['build_count_wood','build_count_frame','build_count_mix',\n",
    "                                'build_count_slag','build_count_foam','build_count_block',\n",
    "                                'build_count_panel','build_count_monolith','build_count_brick'] ].sum( axis=1 )\n",
    "\n",
    "big_df['Good_build'] = (big_df['build_count_wood'] + big_df['build_count_frame'] + big_df['build_count_mix'] + \n",
    "                        big_df['build_count_slag'] + big_df['build_count_foam']) / big_df['N_build']\n",
    "\n",
    "big_df['Bad_build' ] = (big_df['build_count_block']+ big_df['build_count_panel'] + big_df['build_count_monolith'] + \n",
    "                        big_df['build_count_brick'] ) / big_df['N_build']\n",
    "\n",
    "big_df['Good_build'] = big_df['Good_build'].fillna( big_df['Good_build'].median() )\n",
    "big_df['Bad_build' ] = big_df['Bad_build' ].fillna( big_df['Bad_build' ].median() )\n",
    "\n",
    "big_df.ix[ big_df['Good_build'] > 1.0 , 'Good_build' ] = big_df['Good_build'].median()\n",
    "big_df.ix[ big_df['Bad_build' ] > 1.0 , 'Bad_build'  ] = big_df['Bad_build' ].median()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Do the above replace for these, make list of those prob\n",
    "power_plants = ['thermal_power_plant_raion','nuclear_reactor_raion']\n",
    "ruin_list    = ['incineration_raion','oil_chemistry_raion','radiation_raion']\n",
    "misc_list    = ['culture_objects_top_25','big_market_raion','detention_facility_raion','big_road1_1line']\n",
    "\n",
    "big_list = power_plants+ruin_list+misc_list\n",
    "\n",
    "for item in big_list:\n",
    "    big_df[item] = big_df[item].replace( {'no':0,'yes':1} ).fillna(0)\n",
    "    \n",
    "big_df['big_market_raion'     ] = big_df['big_market_raion'     ].fillna(0)\n",
    "big_df['nuclear_reactor_raion'] = big_df['nuclear_reactor_raion'].fillna(0) \n",
    "    \n",
    "# Do some data cleaning    \n",
    "big_df['product_type'] = big_df['product_type'].replace( {'Investment':0, 'OwnerOccupier':1} ).fillna(0)\n",
    "big_df['state'       ] = big_df['state'       ].replace( {33.:3.}).fillna(0.)\n",
    "big_df['material'    ] = big_df['material'    ].replace( {3:0})\n",
    "big_df['material'    ] = big_df['material'    ].replace( {6:3}).fillna(0)\n",
    "\n",
    "big_df['floor'    ] = big_df['floor'    ].fillna( 0 )\n",
    "big_df['state'    ] = big_df['state'    ].fillna( 0 )\n",
    "big_df['max_floor'] = big_df['max_floor'].fillna( 0 )\n",
    "\n",
    "\n",
    "# Fill nulls with medians\n",
    "for adj in ['prom_part_5000','life_sq','num_room','kitch_sq']:\n",
    "    big_df[adj] = big_df[adj].fillna( big_df[adj].median() )\n",
    "\n",
    "    \n",
    "    \n",
    "# Fill build year oddballs, far outside range-fill in median\n",
    "# Otherwise, use material to estimate a year\n",
    "# Still outlying? Toss in the new mean\n",
    "big_df   [                              'build_year' ] = big_df['build_year'].replace( {2.00520090e+07:2007} )\n",
    "big_df.ix[ big_df['build_year'] < 1000, 'build_year' ] = big_df['build_year'].mean()\n",
    "big_df.ix[ big_df['build_year'] > 2020, 'build_year' ] = big_df['build_year'].mean()\n",
    "\n",
    "for floor in big_df['max_floor'].unique():\n",
    "    mean = big_df.ix[ big_df['max_floor'] == floor, 'build_year' ].mean()\n",
    "    big_df.ix[ big_df['max_floor'] == floor, 'build_year' ] = big_df.ix[ big_df['max_floor'] == floor, 'build_year' ].fillna( mean )\n",
    "big_df['build_year'] = big_df['build_year'].fillna( big_df['build_year'].mean() )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Put floors in range\n",
    "for flr in ['floor','max_floor']:\n",
    "    big_df.ix[ (big_df[flr] >  2) & (big_df[flr] <=  5), flr ] = 3\n",
    "    big_df.ix[ (big_df[flr] >  5) & (big_df[flr] <= 10), flr ] = 4\n",
    "    big_df.ix[ (big_df[flr] > 10) & (big_df[flr] <= 30), flr ] = 5\n",
    "    big_df.ix[ (big_df[flr] > 30) & (big_df[flr] <= 50), flr ] = 6\n",
    "    big_df.ix[ (big_df[flr] > 50)                      , flr ] = 7\n",
    "big_df.ix[ big_df['floor'] > big_df['max_floor'], 'max_floor' ] = big_df.ix[ big_df['floor'] > big_df['max_floor'], 'floor'] \n",
    "\n",
    "big_df['sub_area'] = rv.numerize_col( big_df, 'sub_area' )\n",
    "\n",
    "\n",
    "\n",
    "# Take the material, and break it into binary classification\n",
    "foo = rv.binary_classification( big_df[ ['material'] ] )\n",
    "for col in foo.columns.values:\n",
    "    big_df[col] = foo[col]\n",
    "big_df = big_df.drop( 'material', axis = 1 )\n",
    "\n",
    "\n",
    "# Take the ecology, set up binary classifiction\n",
    "big_df['ecology'] = big_df['ecology'].replace( {'no data':0, 'poor':1, 'satisfactory':2, 'good':3, 'excellent':4} )\n",
    "foo = rv.binary_classification( big_df[ ['ecology'] ] )\n",
    "for col in foo.columns.values:\n",
    "    big_df[col] = foo[col]\n",
    "big_df = big_df.drop( 'ecology', axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This stuff had near 0 correlation to final price\n",
    "drop_list_age      = ['0_6_all','0_6_male','0_6_female','7_14_all','7_14_male','7_14_female','0_17_all','0_17_male','0_17_female','16_29_all','16_29_male','16_29_female','0_13_all','0_13_male','0_13_female']\n",
    "drop_list_aGroup   = ['young_all', 'young_male', 'young_female', 'work_all', 'work_male', 'work_female', 'ekder_all', 'ekder_male', 'ekder_female']\n",
    "drop_list_pop      = ['full_all','male_f','female_f']\n",
    "drop_list_neigh    = ['raion_popul']\n",
    "drop_list_green    = ['green_part_3000','green_part_2000','green_part_1500','green_part_1000','green_part_500']\n",
    "drop_list_school   = ['preschool_km','school_education_centers_top_20_raion','school_quota','preschool_quota','school_quota','children_preschool','preschool_education_centers_raion']\n",
    "drop_list_build    = ['build_count_wood','build_count_frame','build_count_mix','build_count_slag','build_count_foam','build_count_block','build_count_panel','build_count_monolith','build_count_brick','build_count_before_1920','build_count_1921-1945','build_count_1946-1970','build_count_1971-1995','build_count_after_1995']\n",
    "drop_list_auto     = ['metro_km_avto','metro_min_walk','metro_km_walk','ID_metro']\n",
    "drop_list_railroad = ['railroad_station_avto_km', 'railroad_station_walk_min', 'railroad_station_walk_km', 'ID_railroad_station_avto', 'ID_railroad_station_walk', 'railroad_1line','railroad_terminal_raion','ID_railroad_terminal'] \n",
    "drop_list_metro    = ['ID_metro', 'metro_km_avto', 'metro_min_walk', 'metro_km_walk']\n",
    "drop_list_sport    = ['sport_objects_raion', 'public_transport_station_min_walk', 'sport_count_500', 'sport_count_1000', 'sport_count_1500', 'sport_count_2000', 'sport_count_3000']\n",
    "drop_list_office   = ['office_raion',  'office_count_500', 'office_count_5000', 'office_sqm_500', 'office_count_1000', 'office_sqm_1000', 'office_count_1500', 'office_sqm_1500', 'office_count_2000', 'office_sqm_2000', 'office_count_3000', 'office_sqm_3000' ]\n",
    "\n",
    "\n",
    "drop_list_misc   = ['hospital_beds_raion','university_top_20_raion','public_transport_station_min_walk','additional_education_raion',\n",
    "                    'culture_objects_top_25_raion','shopping_centers_raion','water_1line','ID_bus_terminal','big_road1_1line',\n",
    "                    'green_zone_part', 'indust_part', 'green_part_5000', 'prom_part_5000', 'metro_min_avto', \n",
    "                    'railroad_station_avto_min', 'office_sqm_5000','trc_sqm_5000', 'Bad_build']\n",
    "\n",
    "drop_list_power  = ['thermal_power_plant_raion']\n",
    "drop_list_ruin   = ['incineration_raion','oil_chemistry_raion','radiation_raion']\n",
    "drop_list_market = ['market_count_500','market_count_1000','market_count_1500','market_count_2000','market_count_3000']\n",
    "drop_list_info   = ['raion_build_count_with_material_info','raion_build_count_with_builddate_info']\n",
    "drop_list_road   = ['ID_big_road1', 'ID_big_road2']\n",
    "drop_list_indus  = ['prom_part_500', 'prom_part_1000', 'prom_part_1500', 'prom_part_2000', 'prom_part_3000']\n",
    "drop_list_mall   = ['trc_count_500', 'trc_sqm_500', 'trc_count_1000', 'trc_sqm_1000', 'trc_count_1500', 'trc_sqm_1500', 'trc_count_2000', 'trc_sqm_2000', 'trc_count_3000', 'trc_sqm_3000']\n",
    "\n",
    "drop_list_church     = ['church_count_500', 'church_count_1000', 'church_count_1500', 'church_count_2000', 'church_count_3000']\n",
    "drop_list_mosque     = ['mosque_count_500', 'mosque_count_1000', 'mosque_count_1500', 'mosque_count_2000', 'mosque_count_3000']\n",
    "drop_list_leisure    = ['leisure_count_500', 'leisure_count_1000', 'leisure_count_1500', 'leisure_count_2000', 'leisure_count_3000']\n",
    "drop_list_big_church = ['big_church_count_500', 'big_church_count_1000', 'big_church_count_1500', 'big_church_count_2000', 'big_church_count_3000']\n",
    "\n",
    "\n",
    "super_list = drop_list_age    + drop_list_aGroup  + drop_list_pop        + drop_list_neigh    + drop_list_green  + \\\n",
    "             drop_list_school + drop_list_build   + drop_list_auto       + drop_list_railroad + drop_list_metro  + \\\n",
    "             drop_list_sport  + drop_list_office  + drop_list_power      + drop_list_ruin     + drop_list_market + \\\n",
    "             drop_list_info   + drop_list_road    + drop_list_indus      + drop_list_mall     + drop_list_church + \\\n",
    "             drop_list_mosque + drop_list_leisure + drop_list_big_church + \\\n",
    "             drop_list_misc\n",
    "\n",
    "big_df = big_df.drop( super_list, axis=1 )\n",
    "\n",
    "# First to do:\n",
    "foo = big_df['cafe_count_5000'           ].copy()\n",
    "bar = big_df['cafe_count_5000_price_high'].copy()\n",
    "# Drop everyhing else\n",
    "big_df = big_df.drop( big_df.columns[ big_df.columns.str.contains('cafe') ], axis=1 )\n",
    "big_df['cafe_count_5000']            = foo.copy()\n",
    "big_df['cafe_count_5000_price_high'] = bar.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'timestamp', 'full_sq', 'life_sq', 'floor', 'max_floor',\n",
       "       'build_year', 'num_room', 'kitch_sq', 'state', 'product_type',\n",
       "       'sub_area', 'area_m', 'children_school',\n",
       "       'school_education_centers_raion', 'healthcare_centers_raion',\n",
       "       'culture_objects_top_25', 'big_market_raion',\n",
       "       'nuclear_reactor_raion', 'detention_facility_raion',\n",
       "       'kindergarten_km', 'school_km', 'park_km', 'green_zone_km',\n",
       "       'industrial_km', 'water_treatment_km', 'cemetery_km',\n",
       "       'incineration_km', 'public_transport_station_km', 'water_km',\n",
       "       'mkad_km', 'ttk_km', 'sadovoe_km', 'bulvar_ring_km', 'kremlin_km',\n",
       "       'big_road1_km', 'big_road2_km', 'railroad_km', 'zd_vokzaly_avto_km',\n",
       "       'bus_terminal_avto_km', 'oil_chemistry_km', 'nuclear_reactor_km',\n",
       "       'radiation_km', 'power_transmission_line_km',\n",
       "       'thermal_power_plant_km', 'ts_km', 'big_market_km',\n",
       "       'market_shop_km', 'fitness_km', 'swim_pool_km', 'ice_rink_km',\n",
       "       'stadium_km', 'basketball_km', 'hospice_morgue_km',\n",
       "       'detention_facility_km', 'public_healthcare_km', 'university_km',\n",
       "       'workplaces_km', 'shopping_centers_km', 'office_km',\n",
       "       'additional_education_km', 'big_church_km', 'church_synagogue_km',\n",
       "       'mosque_km', 'theater_km', 'museum_km', 'exhibition_km',\n",
       "       'catering_km', 'trc_count_5000', 'big_church_count_5000',\n",
       "       'church_count_5000', 'mosque_count_5000', 'leisure_count_5000',\n",
       "       'sport_count_5000', 'market_count_5000', 'N_build', 'Good_build',\n",
       "       'Bad_build', 'material_0.0', 'material_1.0', 'material_2.0',\n",
       "       'material_4.0', 'material_3.0', 'material_5.0', 'ecology_3',\n",
       "       'ecology_2', 'ecology_4', 'ecology_0', 'ecology_1',\n",
       "       'cafe_count_5000', 'cafe_count_5000_price_high'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = big_df.ix[:, big_df.columns.str.contains('raion') ].copy()\n",
    "foo['healthcare_centers_raion'      ] = rv.normalize_column_sigma( foo, 'healthcare_centers_raion'      , lower_bound = False )\n",
    "foo['school_education_centers_raion'] = rv.normalize_column_sigma( foo, 'school_education_centers_raion', lower_bound = False )\n",
    "\n",
    "rain_pca  = rv.generate_reduced_PCA(    foo, 1, contain_str='raion', corr_df=target_price )\n",
    "km_pca    = rv.generate_reduced_PCA( big_df, 1, contain_str='_km'  , corr_df=target_price, sigma_normalize=True, lower_bound = False, col_names='km' )\n",
    "count_pca = rv.generate_reduced_PCA( big_df, 1, contain_str='count', corr_df=target_price, sigma_normalize=True )\n",
    "\n",
    "big_df = big_df.drop( big_df.columns.values[ big_df.columns.str.contains('raion') ], axis=1 )\n",
    "big_df = big_df.drop( big_df.columns.values[ big_df.columns.str.contains(  '_km') ], axis=1 )\n",
    "big_df = big_df.drop( big_df.columns.values[ big_df.columns.str.contains('count') ], axis=1 )\n",
    "\n",
    "big_df[  rain_pca.columns.values[0] ] =  rain_pca\n",
    "big_df[    km_pca.columns.values[0] ] =    km_pca\n",
    "big_df[ count_pca.columns.values[0] ] = count_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'timestamp', 'full_sq', 'life_sq', 'floor', 'max_floor',\n",
       "       'build_year', 'num_room', 'kitch_sq', 'state', 'product_type',\n",
       "       'sub_area', 'area_m', 'children_school', 'culture_objects_top_25',\n",
       "       'N_build', 'Good_build', 'material_0.0', 'material_1.0',\n",
       "       'material_2.0', 'material_4.0', 'material_3.0', 'material_5.0',\n",
       "       'ecology_3', 'ecology_4', 'ecology_1', 'ecology_2', 'ecology_0',\n",
       "       'raion_pca_0', 'km_pca_0', 'count_pca_0'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# log the area\n",
    "big_df['area_m'] = np.log10( big_df['area_m'] )\n",
    "\n",
    "big_df.ix[ big_df['N_build' ] >  800, 'N_build' ] =  800\n",
    "big_df.ix[ big_df['full_sq' ] >  700, 'full_sq' ] =  700\n",
    "big_df.ix[ big_df['life_sq' ] >  100, 'life_sq' ] =  100\n",
    "big_df.ix[ big_df['kitch_sq'] >   20, 'kitch_sq'] =   20\n",
    "big_df.ix[ big_df['num_room'] >    6, 'num_room'] =    6\n",
    "\n",
    "log_list         = [ 'full_sq','life_sq','kitch_sq','N_build','children_school']\n",
    "norm_sigma_upper = [ 'area_m' ]\n",
    "\n",
    "for col in log_list:\n",
    "    big_df[col] = np.log10( big_df[col] + 1 )\n",
    "    big_df[col] = rv.scale_column_sigma( big_df, col, n_sigma=3.0 )\n",
    "    \n",
    "for col in norm_sigma_upper:\n",
    "    big_df[col] = rv.scale_column_sigma( big_df, col, n_sigma=3.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'timestamp', 'full_sq', 'life_sq', 'floor', 'max_floor',\n",
       "       'build_year', 'num_room', 'kitch_sq', 'state', 'product_type',\n",
       "       'sub_area', 'area_m', 'children_school', 'culture_objects_top_25',\n",
       "       'N_build', 'Good_build', 'material_0.0', 'material_1.0',\n",
       "       'material_2.0', 'material_4.0', 'material_3.0', 'material_5.0',\n",
       "       'ecology_3', 'ecology_4', 'ecology_1', 'ecology_2', 'ecology_0',\n",
       "       'raion_pca_0', 'km_pca_0', 'count_pca_0'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in big_df.columns.values[2:]:\n",
    "    big_df[col].hist(bins=20)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state, sub_area need binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "timestamp: date of transaction\n",
    "full_sq: total area in square meters, including loggias, balconies and other non-residential areas\n",
    "life_sq: living area in square meters, excluding loggias, balconies and other non-residential areas\n",
    "floor: for apartments, floor of the building\n",
    "max_floor: number of floors in the building\n",
    "material: wall material\n",
    "build_year: year built\n",
    "num_room: number of living rooms\n",
    "kitch_sq: kitchen area\n",
    "state: apartment condition\n",
    "product_type: owner-occupier purchase or investment\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsub_area: name of the district\\nfull_all: subarea population\\nmale_f, female_f: subarea population by gender\\nyoung_*: population younger than working age\\nwork_*: working-age population\\nekder_*: retirement-age population\\nn_m_{all|male|female}: population between n and m years old\\nbuild_count_*: buildings in the subarea by construction type or year\\nx_count_500: the number of x within 500m of the property\\nx_part_500: the share of x within 500m of the property\\n_sqm_: square meters\\ncafe_count_d_price_p: number of cafes within d meters of the property that have an average bill under p RUB\\ntrc_: shopping malls\\nprom_: industrial zones\\ngreen_: green zones\\nmetro_: subway\\n_avto_: distances by car\\nmkad_: Moscow Circle Auto Road\\nttk_: Third Transport Ring\\nsadovoe_: Garden Ring\\nbulvar_ring_: Boulevard Ring\\nkremlin_: City center\\nzd_vokzaly_: Train station\\noil_chemistry_: Dirty industry\\nts_: Power plant\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "raion=sub_area\n",
    "sub_area: name of the district\n",
    "full_all: subarea population\n",
    "male_f, female_f: subarea population by gender\n",
    "young_*: population younger than working age\n",
    "work_*: working-age population\n",
    "ekder_*: retirement-age population\n",
    "n_m_{all|male|female}: population between n and m years old\n",
    "build_count_*: buildings in the subarea by construction type or year\n",
    "x_count_500: the number of x within 500m of the property\n",
    "x_part_500: the share of x within 500m of the property\n",
    "_sqm_: square meters\n",
    "cafe_count_d_price_p: number of cafes within d meters of the property that have an average bill under p RUB\n",
    "trc_: shopping malls\n",
    "prom_: industrial zones\n",
    "green_: green zones\n",
    "metro_: subway\n",
    "_avto_: distances by car\n",
    "mkad_: Moscow Circle Auto Road\n",
    "ttk_: Third Transport Ring\n",
    "sadovoe_: Garden Ring\n",
    "bulvar_ring_: Boulevard Ring\n",
    "kremlin_: City center\n",
    "zd_vokzaly_: Train station\n",
    "oil_chemistry_: Dirty industry\n",
    "ts_: Power plant\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
